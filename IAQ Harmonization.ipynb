{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the CSV files\n",
    "df_iaq2 = pd.read_csv('/mnt/data/IAQ2.csv')\n",
    "df_iaq3 = pd.read_csv('/mnt/data/IAQ3.csv')\n",
    "df_iaq4 = pd.read_csv('/mnt/data/IAQ4.csv')\n",
    "df_iaq5 = pd.read_csv('/mnt/data/IAQ5.csv')\n",
    "\n",
    "# Combine them into a single dataframe with an additional 'Sensor' column to identify the source\n",
    "df_iaq1['Sensor'] = 'sensor01'\n",
    "df_iaq2['Sensor'] = 'sensor02'\n",
    "df_iaq3['Sensor'] = 'sensor03'\n",
    "df_iaq4['Sensor'] = 'sensor04'\n",
    "df_iaq5['Sensor'] = 'sensor05'\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df_combined = pd.concat([df_iaq1, df_iaq2, df_iaq3, df_iaq4, df_iaq5], ignore_index=True)\n",
    "\n",
    "# Convert the 'PKT' column to datetime format\n",
    "df_combined['PKT'] = pd.to_datetime(df_combined['PKT'])\n",
    "\n",
    "# Verify the combined dataframe structure and data types\n",
    "df_combined.info(), df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478641fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to plot the data for each sensor and parameter\n",
    "def plot_parameter_data(df, parameter):\n",
    "    sensors = df['Sensor'].unique()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    for sensor in sensors:\n",
    "        # Filter the dataframe for each sensor\n",
    "        sensor_data = df[df['Sensor'] == sensor]\n",
    "        plt.plot(sensor_data['PKT'], sensor_data[parameter], label=sensor)\n",
    "\n",
    "    # Calculate the median value for the parameter at each time point\n",
    "    median_values = df.groupby('PKT')[parameter].median().reset_index(name='Median')\n",
    "    plt.plot(median_values['PKT'], median_values['Median'], 'k--', label='Median')\n",
    "\n",
    "    # Calculate the RMSE for each sensor and the median\n",
    "    rmse_values = []\n",
    "    for sensor in sensors:\n",
    "        sensor_data = df[df['Sensor'] == sensor]\n",
    "        merged_data = pd.merge(sensor_data, median_values, on='PKT')\n",
    "        rmse = np.sqrt(mean_squared_error(merged_data[parameter+'_x'], merged_data['Median']))\n",
    "        rmse_values.append(rmse)\n",
    "    \n",
    "    # Plot the median and RMSE on the graph\n",
    "    plt.title(f'{parameter} Data for Sensors\\nRMSE: {np.mean(rmse_values):.2f}')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel(parameter)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show plot and return the average RMSE across all sensors for the parameter\n",
    "    plt.show()\n",
    "    return np.mean(rmse_values)\n",
    "\n",
    "# Now let's plot for each parameter except 'PKT' and 'Sensor'\n",
    "parameters = df_combined.columns.difference(['PKT', 'Sensor'])\n",
    "\n",
    "# This could take some time, so let's plot for one parameter first to check the output\n",
    "average_rmse = plot_parameter_data(df_combined, 'PM 2.5 (ug/m3)')\n",
    "average_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected function to plot the data for each sensor and parameter\n",
    "def plot_parameter_data_corrected(df, parameter):\n",
    "    sensors = df['Sensor'].unique()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Plot each sensor's parameter data\n",
    "    for sensor in sensors:\n",
    "        sensor_data = df[df['Sensor'] == sensor]\n",
    "        plt.plot(sensor_data['PKT'], sensor_data[parameter], label=sensor)\n",
    "\n",
    "    # Calculate and plot the median value for the parameter\n",
    "    median_values = df.groupby('PKT')[parameter].median()\n",
    "    plt.plot(df['PKT'].unique(), median_values, 'k--', label='Median')\n",
    "\n",
    "    # Calculate the RMSE for each sensor\n",
    "    rmse_values = {}\n",
    "    for sensor in sensors:\n",
    "        sensor_data = df[df['Sensor'] == sensor]\n",
    "        rmse = np.sqrt(mean_squared_error(sensor_data[parameter], median_values.reindex(sensor_data['PKT']).values))\n",
    "        rmse_values[sensor] = rmse\n",
    "\n",
    "    # Plot the RMSE on the graph\n",
    "    avg_rmse = np.mean(list(rmse_values.values()))\n",
    "    plt.title(f'{parameter} Data for Sensors\\nRMSE: {avg_rmse:.2f}')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel(parameter)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    return avg_rmse\n",
    "\n",
    "# Let's plot again for PM 2.5 data\n",
    "average_rmse_pm25 = plot_parameter_data_corrected(df_combined, 'PM 2.5 (ug/m3)')\n",
    "average_rmse_pm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a9ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for the month of January\n",
    "df_january = df_combined[df_combined['PKT'].dt.month == 1]\n",
    "\n",
    "# Now let's plot for each parameter for January\n",
    "january_rmses = {}\n",
    "for parameter in parameters:\n",
    "    print(f\"Plotting for {parameter} (January data)...\")\n",
    "    january_rmses[parameter] = plot_parameter_data_corrected(df_january, parameter)\n",
    "\n",
    "# Display the average RMSE for each parameter for January\n",
    "january_rmses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for the date range from January 20, 2024 to January 31, 2024\n",
    "df_january_20_to_31 = df_combined[(df_combined['PKT'] >= '2024-01-20') & (df_combined['PKT'] <= '2024-01-31')]\n",
    "\n",
    "# Now let's plot for each parameter for the specified date range\n",
    "january_20_to_31_rmses = {}\n",
    "for parameter in parameters:\n",
    "    print(f\"Plotting for {parameter} (20 Jan 2024 to 31 Jan 2024 data)...\")\n",
    "    january_20_to_31_rmses[parameter] = plot_parameter_data_corrected(df_january_20_to_31, parameter)\n",
    "\n",
    "# Display the average RMSE for each parameter for the specified date range\n",
    "january_20_to_31_rmses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fb0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Function to create scatter plots with and without intercept for linear regression\n",
    "def scatter_plot_linear_regression(df, parameter):\n",
    "    # Prepare data for linear regression\n",
    "    X_median = df.groupby('PKT')[parameter].median().values.reshape(-1, 1)\n",
    "    y_values = df[parameter].values\n",
    "\n",
    "    # Linear regression with intercept\n",
    "    model_with_intercept = LinearRegression(fit_intercept=True)\n",
    "    model_with_intercept.fit(X_median, y_values)\n",
    "    y_pred_with_intercept = model_with_intercept.predict(X_median)\n",
    "    r2_with_intercept = r2_score(y_values, y_pred_with_intercept)\n",
    "\n",
    "    # Linear regression without intercept\n",
    "    model_without_intercept = LinearRegression(fit_intercept=False)\n",
    "    model_without_intercept.fit(X_median, y_values)\n",
    "    y_pred_without_intercept = model_without_intercept.predict(X_median)\n",
    "    r2_without_intercept = r2_score(y_values, y_pred_without_intercept)\n",
    "\n",
    "    # Plot scatter and regression line with intercept\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X_median, y_values, alpha=0.5)\n",
    "    plt.plot(X_median, y_pred_with_intercept, color='red', linewidth=2)\n",
    "    plt.title(f'{parameter} with Intercept\\ny = {model_with_intercept.coef_[0]:.2f}x + {model_with_intercept.intercept_:.2f} | R² = {r2_with_intercept:.2f}')\n",
    "    plt.xlabel('Median')\n",
    "    plt.ylabel(parameter)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot scatter and regression line without intercept\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_median, y_values, alpha=0.5)\n",
    "    plt.plot(X_median, y_pred_without_intercept, color='green', linewidth=2)\n",
    "    plt.title(f'{parameter} without Intercept\\ny = {model_without_intercept.coef_[0]:.2f}x | R² = {r2_without_intercept:.2f}')\n",
    "    plt.xlabel('Median')\n",
    "    plt.ylabel(parameter)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function for the PM 2.5 parameter\n",
    "scatter_plot_linear_regression(df_january_20_to_31, 'PM 2.5 (ug/m3)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create scatter plots with and without intercept for linear regression, corrected for paired data\n",
    "def scatter_plot_linear_regression_corrected(df, parameter):\n",
    "    # Calculate median values for each timestamp\n",
    "    median_values = df.groupby('PKT')[parameter].median().reset_index(name='Median')\n",
    "    # Merge the median values with the original dataframe on the timestamp\n",
    "    df_with_median = pd.merge(df, median_values, on='PKT')\n",
    "    \n",
    "    # Prepare data for linear regression\n",
    "    X_median = df_with_median['Median'].values.reshape(-1, 1)\n",
    "    y_values = df_with_median[parameter].values\n",
    "\n",
    "    # Perform linear regression with intercept\n",
    "    model_with_intercept = LinearRegression(fit_intercept=True)\n",
    "    model_with_intercept.fit(X_median, y_values)\n",
    "    y_pred_with_intercept = model_with_intercept.predict(X_median)\n",
    "    r2_with_intercept = r2_score(y_values, y_pred_with_intercept)\n",
    "\n",
    "    # Perform linear regression without intercept\n",
    "    model_without_intercept = LinearRegression(fit_intercept=False)\n",
    "    model_without_intercept.fit(X_median, y_values)\n",
    "    y_pred_without_intercept = model_without_intercept.predict(X_median)\n",
    "    r2_without_intercept = r2_score(y_values, y_pred_without_intercept)\n",
    "\n",
    "    # Scatter plot and regression line with intercept\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X_median, y_values, alpha=0.5)\n",
    "    plt.plot(X_median, y_pred_with_intercept, color='red', linewidth=2)\n",
    "    plt.title(f'{parameter} with Intercept\\ny = {model_with_intercept.coef_[0]:.2f}x + {model_with_intercept.intercept_:.2f}\\nR² = {r2_with_intercept:.2f}')\n",
    "    plt.xlabel('Median')\n",
    "    plt.ylabel(parameter)\n",
    "\n",
    "    # Scatter plot and regression line without intercept\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_median, y_values, alpha=0.5)\n",
    "    plt.plot(X_median, y_pred_without_intercept, color='green', linewidth=2)\n",
    "    plt.title(f'{parameter} without Intercept\\ny = {model_without_intercept.coef_[0]:.2f}x\\nR² = {r2_without_intercept:.2f}')\n",
    "    plt.xlabel('Median')\n",
    "    plt.ylabel(parameter)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the corrected function for the PM 2.5 parameter\n",
    "scatter_plot_linear_regression_corrected(df_january_20_to_31, 'PM 2.5 (ug/m3)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d53f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll now create scatter plots with and without intercept for linear regression for all parameters\n",
    "for parameter in parameters:\n",
    "    print(f\"Creating scatter plots for {parameter}...\")\n",
    "    scatter_plot_linear_regression_corrected(df_january_20_to_31, parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51488e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold regression results for each parameter\n",
    "regression_results = {\n",
    "    'Parameter': [],\n",
    "    'With Intercept Coefficient': [],\n",
    "    'With Intercept Intercept': [],\n",
    "    'With Intercept R2': [],\n",
    "    'Without Intercept Coefficient': [],\n",
    "    'Without Intercept R2': []\n",
    "}\n",
    "\n",
    "# Function to calculate regression results and add to the dictionary\n",
    "def calculate_regression_results(df, parameter):\n",
    "    # Calculate median values for each timestamp\n",
    "    median_values = df.groupby('PKT')[parameter].median().reset_index(name='Median')\n",
    "    # Merge the median values with the original dataframe on the timestamp\n",
    "    df_with_median = pd.merge(df, median_values, on='PKT')\n",
    "    \n",
    "    # Prepare data for linear regression\n",
    "    X_median = df_with_median['Median'].values.reshape(-1, 1)\n",
    "    y_values = df_with_median[parameter].values\n",
    "\n",
    "    # Linear regression with intercept\n",
    "    model_with_intercept = LinearRegression(fit_intercept=True)\n",
    "    model_with_intercept.fit(X_median, y_values)\n",
    "    r2_with_intercept = r2_score(y_values, model_with_intercept.predict(X_median))\n",
    "\n",
    "    # Linear regression without intercept\n",
    "    model_without_intercept = LinearRegression(fit_intercept=False)\n",
    "    model_without_intercept.fit(X_median, y_values)\n",
    "    r2_without_intercept = r2_score(y_values, model_without_intercept.predict(X_median))\n",
    "\n",
    "    # Add results to the dictionary\n",
    "    regression_results['Parameter'].append(parameter)\n",
    "    regression_results['With Intercept Coefficient'].append(model_with_intercept.coef_[0])\n",
    "    regression_results['With Intercept Intercept'].append(model_with_intercept.intercept_)\n",
    "    regression_results['With Intercept R2'].append(r2_with_intercept)\n",
    "    regression_results['Without Intercept Coefficient'].append(model_without_intercept.coef_[0])\n",
    "    regression_results['Without Intercept R2'].append(r2_without_intercept)\n",
    "\n",
    "# Calculate regression results for all parameters\n",
    "for parameter in parameters:\n",
    "    calculate_regression_results(df_january_20_to_31, parameter)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "df_regression_results = pd.DataFrame(regression_results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_csv_path = '/mnt/data/regression_results_summary.csv'\n",
    "df_regression_results.to_csv(results_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95144040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sanitize parameter names for use in filenames\n",
    "def sanitize_filename(name):\n",
    "    return name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_per_\")\n",
    "\n",
    "# Function to create and save CSV for each parameter with median values included, with filename correction\n",
    "def save_parameter_data_with_median_corrected(df, parameter):\n",
    "    # Calculate median values for each timestamp\n",
    "    median_values = df.groupby('PKT')[parameter].median().reset_index(name='Median')\n",
    "    # Merge the median values with the original dataframe on the timestamp\n",
    "    df_with_median = pd.merge(df, median_values, on='PKT', how='left')\n",
    "    # Select only the relevant columns to save\n",
    "    df_to_save = df_with_median[['PKT', 'Sensor', parameter, 'Median']]\n",
    "    # Sanitize filename\n",
    "    filename = sanitize_filename(parameter)\n",
    "    # Save to CSV\n",
    "    file_path = f'/mnt/data/{filename}_data_with_median.csv'\n",
    "    df_to_save.to_csv(file_path, index=False)\n",
    "    return file_path\n",
    "\n",
    "# Save the CSV for each parameter with corrected filenames\n",
    "parameter_csv_paths_corrected = {}\n",
    "\n",
    "for parameter in parameters:\n",
    "    parameter_csv_paths_corrected[parameter] = save_parameter_data_with_median_corrected(df_january_20_to_31, parameter)\n",
    "\n",
    "parameter_csv_paths_corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resample sensor data to hourly for all sensors and save to CSV\n",
    "def save_hourly_all_sensors_data_with_median(df, parameter):\n",
    "    # Sanitize filename\n",
    "    filename = sanitize_filename(parameter)\n",
    "    \n",
    "    # Empty DataFrame to store hourly data for all sensors\n",
    "    hourly_all_sensors_data = pd.DataFrame()\n",
    "    \n",
    "    # Process each sensor's data\n",
    "    for sensor in df['Sensor'].unique():\n",
    "        # Filter data for the current sensor\n",
    "        sensor_data = df[df['Sensor'] == sensor]\n",
    "        # Set the index to the timestamp for resampling\n",
    "        sensor_data = sensor_data.set_index('PKT')\n",
    "        # Resample data to hourly, calculating the mean for each hour\n",
    "        hourly_data = sensor_data[parameter].resample('H').mean().reset_index(name=f'{sensor}_{parameter}')\n",
    "        # If the hourly DataFrame is empty, initialize it with data from the first sensor\n",
    "        if hourly_all_sensors_data.empty:\n",
    "            hourly_all_sensors_data = hourly_data\n",
    "        else:\n",
    "            # If not empty, merge with the existing data (this aligns all sensors to the same hourly timestamps)\n",
    "            hourly_all_sensors_data = pd.merge(hourly_all_sensors_data, hourly_data, on='PKT', how='outer')\n",
    "\n",
    "    # Calculate hourly median values for the parameter across all sensors\n",
    "    hourly_median = df.resample('H', on='PKT')[parameter].median().reset_index(name='Median')\n",
    "    # Merge the hourly median values with the hourly data\n",
    "    hourly_all_sensors_data_with_median = pd.merge(hourly_all_sensors_data, hourly_median, on='PKT', how='left')\n",
    "    \n",
    "    # Save to CSV\n",
    "    file_path = f'/mnt/data/hourly_all_sensors_{filename}_data_with_median.csv'\n",
    "    hourly_all_sensors_data_with_median.to_csv(file_path, index=False)\n",
    "    return file_path\n",
    "\n",
    "# Save the CSV for each hourly resampled parameter including all sensors\n",
    "hourly_all_sensors_parameter_csv_paths = {}\n",
    "\n",
    "for parameter in parameters:\n",
    "    hourly_all_sensors_parameter_csv_paths[parameter] = save_hourly_all_sensors_data_with_median(df_january_20_to_31, parameter)\n",
    "\n",
    "hourly_all_sensors_parameter_csv_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f640f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
